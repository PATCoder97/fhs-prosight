---
name: Implement service layer core functions
status: closed
created: 2026-01-12T07:14:18Z
updated: 2026-01-12T07:24:05Z
completed: 2026-01-12T09:12:16Z
github: https://github.com/PATCoder97/fhs-prosight/issues/57
depends_on: [54, 55, 56]
parallel: false
conflicts_with: []
---

# Task: Implement service layer core functions

## Description
Implement the business logic layer for PIDMS operations including check_and_upsert_keys, search_keys, and get_product_summary functions. This layer orchestrates database operations and external API calls.

## Acceptance Criteria
- [ ] Service file created at `backend/app/services/pidms_service.py`
- [ ] check_and_upsert_keys() function: calls PIDKey client, upserts to DB, returns summary
- [ ] search_keys() function: fuzzy search with filters and pagination
- [ ] get_product_summary() function: aggregates statistics grouped by product
- [ ] All functions use async/await pattern
- [ ] Database transactions are atomic with rollback on errors
- [ ] Comprehensive error handling and logging
- [ ] Type hints for all parameters and return values

## Technical Details

**File:** `backend/app/services/pidms_service.py`

**Core Functions:**
```python
import logging
from typing import List, Dict, Optional
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, or_, func, and_
from fastapi import HTTPException

from app.models.pidms_key import PIDMSKey
from app.integrations.pidkey_client import PIDKeyClient

logger = logging.getLogger(__name__)


async def check_and_upsert_keys(
    db: AsyncSession,
    keys_list: List[str],
    pidkey_client: PIDKeyClient
) -> dict:
    """
    Check keys against PIDKey.com and upsert to database

    Returns:
        {
            "success": bool,
            "summary": {"total_keys": int, "new_keys": int, "updated_keys": int, "errors": int},
            "results": [{"keyname": str, "status": str, "prd": str, "remaining": int}]
        }
    """
    try:
        # Step 1: Call PIDKey.com API
        api_response = await pidkey_client.check_keys(keys_list)

        total_keys = len(api_response)
        new_keys = 0
        updated_keys = 0
        errors = 0
        results = []

        # Step 2: Upsert each key
        for key_data in api_response:
            keyname = key_data.get("keyname")

            # Check if exists
            stmt = select(PIDMSKey).where(PIDMSKey.keyname == keyname)
            result = await db.execute(stmt)
            existing_key = result.scalar_one_or_none()

            if existing_key:
                # UPDATE
                for field, value in key_data.items():
                    setattr(existing_key, field, value)
                updated_keys += 1
                status = "updated"
            else:
                # INSERT
                new_key = PIDMSKey(**key_data)
                db.add(new_key)
                new_keys += 1
                status = "new"

            results.append({
                "keyname": keyname,
                "keyname_with_dash": key_data.get("keyname_with_dash"),
                "status": status,
                "prd": key_data.get("prd"),
                "remaining": key_data.get("remaining")
            })

        await db.commit()

        return {
            "success": True,
            "summary": {
                "total_keys": total_keys,
                "new_keys": new_keys,
                "updated_keys": updated_keys,
                "errors": errors
            },
            "results": results
        }

    except Exception as e:
        await db.rollback()
        logger.error(f"check_and_upsert_keys failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to check keys: {str(e)}")


async def search_keys(
    db: AsyncSession,
    product: Optional[str] = None,
    min_remaining: Optional[int] = None,
    max_remaining: Optional[int] = None,
    blocked: Optional[int] = None,
    page: int = 1,
    page_size: int = 50
) -> dict:
    """
    Search keys with fuzzy product matching and filters
    """
    # Validate pagination
    if page < 1:
        raise HTTPException(status_code=422, detail="Page must be >= 1")
    if page_size < 1 or page_size > 100:
        raise HTTPException(status_code=422, detail="Page size must be 1-100")

    # Build query
    query = select(PIDMSKey)

    if product:
        query = query.where(PIDMSKey.prd.ilike(f"%{product}%"))
    if min_remaining is not None:
        query = query.where(PIDMSKey.remaining >= min_remaining)
    if max_remaining is not None:
        query = query.where(PIDMSKey.remaining <= max_remaining)
    if blocked is not None:
        query = query.where(PIDMSKey.blocked == blocked)

    # Count total
    count_query = select(func.count()).select_from(query.subquery())
    total = (await db.execute(count_query)).scalar()

    # Apply sorting and pagination
    query = query.order_by(PIDMSKey.prd, PIDMSKey.remaining.desc())
    offset = (page - 1) * page_size
    query = query.offset(offset).limit(page_size)

    # Execute
    result = await db.execute(query)
    keys = result.scalars().all()

    return {
        "total": total,
        "page": page,
        "page_size": page_size,
        "results": keys
    }


async def get_product_summary(db: AsyncSession) -> dict:
    """
    Get aggregated statistics grouped by product
    """
    stmt = select(
        PIDMSKey.prd,
        func.count(PIDMSKey.id).label("key_count"),
        func.sum(PIDMSKey.remaining).label("total_remaining"),
        func.avg(PIDMSKey.remaining).label("avg_remaining")
    ).group_by(PIDMSKey.prd)

    result = await db.execute(stmt)
    rows = result.all()

    products = []
    for row in rows:
        products.append({
            "prd": row.prd,
            "key_count": row.key_count,
            "total_remaining": int(row.total_remaining or 0),
            "avg_remaining": round(row.avg_remaining or 0, 2),
            "low_inventory": (row.total_remaining or 0) < 5
        })

    return {"products": products}
```

**Files Affected:**
- `backend/app/services/pidms_service.py` (new)

## Dependencies
- [x] Task 001: Database model must exist
- [x] Task 002: Schemas must exist
- [x] Task 003: PIDKey client must exist

## Effort Estimate
- Size: L
- Hours: 6-8 hours
- Parallel: false (depends on tasks 001, 55, 003)

## Definition of Done
- [x] All three core functions implemented
- [x] Database transactions tested (commit and rollback)
- [x] Error handling verified
- [x] Logging added for debugging
- [x] Type hints complete
- [x] Functions tested with mock data
